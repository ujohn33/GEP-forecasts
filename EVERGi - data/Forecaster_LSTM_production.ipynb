{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from workalendar.europe import Belgium\n",
    "import itertools\n",
    "import sys\n",
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "# Deep learning: \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import itertools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidata = pd.read_pickle('./building1_holidays.pkl')\n",
    "holidata.index = holidata.index.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidata_user = holidata[-672*3+96*0:-672*2+96*0]\n",
    "holidata_user.to_csv(deep_learner.import_file_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidata_user = holidata[-672*38+96*3:-672*37+96*3]\n",
    "holidata_user.to_csv(deep_learner.import_file_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_range = holidata[-672*37+96*3:-672*36+96*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DeepModelTS' object has no attribute 'configuration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-de82588fa6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0mdeep_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     deep_learner = DeepModelTS(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DeepModelTS' object has no attribute 'configuration'"
     ]
    }
   ],
   "source": [
    "class DeepModelTS():\n",
    "    \"\"\"\n",
    "    A class to create a deep time series model\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        #data: pd.DataFrame,\n",
    "        data_path: str,\n",
    "        Y_var: str,\n",
    "        model_save: str,\n",
    "        model_load: str,\n",
    "        import_file_path: str,\n",
    "        export_file_path: str,\n",
    "        lag: int,\n",
    "        lag2: int,\n",
    "        LSTM_layer_depth: int, \n",
    "        epochs=10, \n",
    "        batch_size=256,\n",
    "        train_test_split=0,\n",
    "        n_test = 96,\n",
    "        holi_var = 'working day',\n",
    "        hour_var_sin = 'hour of day_sin',\n",
    "        hour_var_cos = 'hour of day_cos',\n",
    "        day_week_sin = 'day of week_sin',\n",
    "        day_week_cos = 'day of week_cos',\n",
    "        month_sin = 'month_sin',\n",
    "        month_cos = 'month_cos',\n",
    "        minutes_sin = 'minutes_sin',\n",
    "        minutes_cos = 'minutes_cos',\n",
    "\n",
    "    ):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.data = pd.read_csv(data_path, index_col=0)\n",
    "        #self.data = data\n",
    "        self.import_file_path = import_file_path\n",
    "        #self.data_user = pd.read_csv(import_file_path, index_col=0)\n",
    "        #self.data_user.index = pd.to_datetime(self.data_user.index)\n",
    "        self.model_save = model_save\n",
    "        self.model_load = model_load\n",
    "        self.export_file_path = export_file_path\n",
    "        self.Y_var = Y_var \n",
    "        self.holi_var = holi_var\n",
    "        self.hour_var_sin = hour_var_sin\n",
    "        self.hour_var_cos = hour_var_cos\n",
    "        self.day_week_sin = day_week_sin\n",
    "        self.day_week_cos = day_week_cos\n",
    "        self.month_sin = month_sin\n",
    "        self.month_cos = month_cos\n",
    "        self.minutes_sin = minutes_sin\n",
    "        self.minutes_cos = minutes_cos\n",
    "        self.lag = lag \n",
    "        self.lag2 = lag2\n",
    "        self.LSTM_layer_depth = LSTM_layer_depth\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.train_test_split = train_test_split\n",
    "        self.n_test = n_test\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess(dataframe):\n",
    "        dataframe.index = pd.to_datetime(dataframe.index)\n",
    "        cal = Belgium()\n",
    "        years = list(range(2014, 2025))\n",
    "        holidays = []\n",
    "        for year in years:\n",
    "            holidays.extend(cal.holidays(year))\n",
    "        dataframe = dataframe.sort_index()\n",
    "        dataframe['working day'] = dataframe.index.map(cal.is_working_day)\n",
    "        dataframe['hour of day'] = dataframe.index.hour\n",
    "        dataframe['day of week'] = dataframe.index.dayofweek\n",
    "        dataframe['date'] = dataframe.index.date\n",
    "        dataframe['month'] = dataframe.index.month\n",
    "        dataframe['minutes'] = dataframe.index.minute\n",
    "        # we encode cynical data into two dimensions using a sine and cosine transformations\n",
    "        def encode(data, col, max_val):\n",
    "            data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "            data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "            return data\n",
    "        dataframe = encode(dataframe, 'hour of day', 23)\n",
    "        dataframe = encode(dataframe, 'day of week', 6)\n",
    "        dataframe = encode(dataframe, 'month', 12)\n",
    "        dataframe = encode(dataframe, 'minutes', 60)\n",
    "        dataframe = dataframe.drop(['hour of day', 'day of week', 'month', 'minutes'], axis=1)\n",
    "        dataframe = dataframe.fillna(method='ffill')\n",
    "        return dataframe\n",
    "    \n",
    "    @staticmethod    \n",
    "    def plot_train_history(model):\n",
    "        '''\n",
    "        Convergence plots to have an idea on how the training performs\n",
    "        '''\n",
    "        loss = model.history.history['loss']\n",
    "        val_loss = model.history.history['val_loss']\n",
    "        plt.figure()\n",
    "        plt.plot(range(len(loss)), loss, 'b', label='Training loss')\n",
    "        plt.plot(range(len(val_loss)), val_loss, 'r', label='Validation loss')\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Losses')\n",
    "        plt.title('Training and validation losses')\n",
    "        plt.legend()\n",
    "        plt.show() \n",
    "    \n",
    "    @staticmethod\n",
    "    def validation(forecasted, real, parameter):\n",
    "        ''' \n",
    "        compute some important parameters to compare forecasting results\n",
    "        '''\n",
    "        value = 0\n",
    "        value_1 = 0\n",
    "        value_2 = 0\n",
    "\n",
    "        if parameter == 'SMAPE':\n",
    "            for i in range(len(forecasted)):\n",
    "                if real[i] + forecasted[i] == 0:\n",
    "                    value += 0\n",
    "                else: \n",
    "                    value += ((abs(real[i] - forecasted[i])) / (real[i] + forecasted[i])) * 100\n",
    "            final_value = value / len(forecasted)  \n",
    "\n",
    "        elif parameter == 'MAPE':\n",
    "            for i in range(len(forecasted)):\n",
    "                if real[i] == 0:\n",
    "                    value += 0\n",
    "                else: \n",
    "                    value += (abs(real[i] - forecasted[i]))/real[i]\n",
    "            final_value = value / len(forecasted) * 100\n",
    "\n",
    "        elif parameter == 'RMSE':\n",
    "            for i in range(len(forecasted)):\n",
    "                value += (real[i] - forecasted[i]) ** 2\n",
    "            final_value = (value / len(forecasted)) ** (1 / 2) \n",
    "\n",
    "        elif parameter == 'R':\n",
    "            for i in range(len(forecasted)):\n",
    "                value += (real[i] - np.mean(real)) * (forecasted[i] - np.mean(forecasted))\n",
    "                value_1 += (real[i] - np.mean(real)) ** 2\n",
    "                value_2 += (forecasted[i] - np.mean(forecasted)) ** 2\n",
    "\n",
    "            if value_1 == 0 or value_2 == 0:\n",
    "                final_value = 100\n",
    "            else:\n",
    "                final_value = (value / ((value_1 ** (1 / 2)) * (value_2 ** (1 / 2))))*100\n",
    "\n",
    "        return final_value\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_X_Y(ts: list, holiday: list, hour_cos: list, hour_sin: list, week_cos: list, week_sin: list, month_cos: list, month_sin: list, minute_cos: list, minute_sin: list, lag: int, lag2: int) -> tuple:\n",
    "        \"\"\"\n",
    "        A method to create X and Y matrix from a time series list for the training of \n",
    "        deep learning models \n",
    "        \"\"\"\n",
    "        X, Y = [], []\n",
    "\n",
    "        if len(ts) - lag <= 0:\n",
    "            X.append(ts)\n",
    "        else:\n",
    "            for i in range(len(ts) - lag2):\n",
    "                Y.append(ts[i + lag2])\n",
    "                # Substacted 96 for not knowing the day before\n",
    "                #ab = list(itertools.chain([holiday[i + lag]], [hour_cos[i + lag]], [hour_sin[i + lag]], [week_cos[i + lag]], [week_sin[i + lag]], [minute_cos[i + lag]], [minute_sin[i + lag]], [month_cos[i + lag]], [month_sin[i + lag]]))\n",
    "                #ab = list(itertools.chain([ts[i+lag - lag]], [ts[i+lag - lag2]], [holiday[i + lag]], [hour_cos[i + lag]], [hour_sin[i + lag]], [week_cos[i + lag]], [week_sin[i + lag]], [minute_cos[i + lag]], [minute_sin[i + lag]], [month_cos[i + lag]], [month_sin[i + lag]]))\n",
    "                ab = list(itertools.chain([ts[i+lag2 - lag]], [ts[i+lag2 - lag2]], [holiday[i + lag2]], [hour_cos[i + lag2]], [hour_sin[i + lag2]], [week_cos[i + lag2]], [week_sin[i + lag2]], [minute_cos[i + lag2]], [minute_sin[i + lag2]], [month_cos[i + lag2]], [month_sin[i + lag2]]))\n",
    "                X.append(ab)\n",
    "                #X.append(ts[i:(i + lag - 96)] + [holiday[i + lag]] + [hour_cos[i + lag]] + [hour_sin[i + lag]] + )\n",
    "        \n",
    "        X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "        # Reshaping the X array to an LSTM input shape \n",
    "        X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "        return X, Y         \n",
    "\n",
    "    def create_data_for_NN(\n",
    "        self,\n",
    "        use_last_n=None, ahead=False):\n",
    "        \"\"\"\n",
    "        A method to create data for the neural network model\n",
    "        \"\"\"\n",
    "        self.data = self.preprocess(self.data)\n",
    "        #print(self.data.columns.values)\n",
    "        \n",
    "        # Extracting the main variable we want to model/forecast\n",
    "        y = self.data[self.Y_var].tolist()\n",
    "        y_holiday = self.data[self.holi_var].tolist()\n",
    "        y_hour_cos = self.data[self.hour_var_cos].tolist()\n",
    "        y_hour_sin = self.data[self.hour_var_sin].tolist()\n",
    "        y_weekday_cos = self.data[self.day_week_cos].tolist()\n",
    "        y_weekday_sin = self.data[self.day_week_sin].tolist()\n",
    "        y_month_cos = self.data[self.month_cos].tolist()\n",
    "        y_month_sin = self.data[self.month_sin].tolist()\n",
    "        y_minute_cos = self.data[self.minutes_cos].tolist()\n",
    "        y_minute_sin = self.data[self.minutes_sin].tolist()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Subseting the time series if needed\n",
    "        if use_last_n is not None:\n",
    "            y = y[-use_last_n:]\n",
    "            y_holiday = y_holiday[-use_last_n:]\n",
    "            y_hour_cos = y_hour_cos[-use_last_n:]\n",
    "            y_hour_sin = y_hour_sin[-use_last_n:]\n",
    "            y_weekday_cos = y_weekday_cos[-use_last_n:]\n",
    "            y_weekday_sin = y_weekday_sin[-use_last_n:]\n",
    "            y_month_cos = y_month_cos[-use_last_n:]\n",
    "            y_month_sin = y_month_sin[-use_last_n:]\n",
    "            y_minute_cos = y_minute_cos[-use_last_n:]\n",
    "            y_minute_sin =  y_minute_sin[-use_last_n:]\n",
    "\n",
    "        # The X matrix will hold the lags of Y \n",
    "        X, Y = self.create_X_Y(y, y_holiday, y_hour_cos, y_hour_sin, y_weekday_cos, y_weekday_sin, y_month_cos, y_month_sin, y_minute_cos, y_minute_sin, self.lag, self.lag2)\n",
    "\n",
    "        # Creating training and test sets \n",
    "        X_train = X\n",
    "        X_val = []\n",
    "        X_test = []\n",
    "\n",
    "        Y_train = Y\n",
    "        Y_val = []\n",
    "        Y_test = []\n",
    "        if ahead == False:\n",
    "            if self.train_test_split > 0:\n",
    "                index = round((len(X) - self.n_test) * self.train_test_split)\n",
    "                X_train = X[:(len(X) - index)]\n",
    "                X_val = X[(len(X) - index):- self.n_test]\n",
    "                X_test = X[-self.n_test:]     \n",
    "\n",
    "                Y_train = Y[:(len(X) - index)]\n",
    "                Y_val = Y[(len(X) - index):- self.n_test]\n",
    "                Y_test = Y[-self.n_test:]\n",
    "        #print(X_train.shape)\n",
    "        #print(Y_train.shape)\n",
    "        return X_train, X_val, X_test, Y_train, Y_val, Y_test\n",
    "   \n",
    "    def save_model(self, model):\n",
    "        model_json = model.to_json()\n",
    "        with open(self.model_save+'.json', \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(self.model_save+'.h5')\n",
    "          \n",
    "    def load_model(self):\n",
    "        # load json and create model\n",
    "        json_file = open(self.model_load+\".json\", 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        self.model.load_weights(self.model_load+\".h5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "    \n",
    "    def LSTModel(self):\n",
    "        \"\"\"\n",
    "        A method to fit the LSTM model \n",
    "        \"\"\"\n",
    "        # Getting the data \n",
    "        X_train, X_val, X_test, Y_train, Y_val, Y_test = self.create_data_for_NN()\n",
    "        # Defining the model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(self.LSTM_layer_depth, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='msle')\n",
    "        \n",
    "        # Setting up early stopping\n",
    "        earlyStop=EarlyStopping(monitor=\"val_loss\",verbose=1,mode='min',patience=7)\n",
    "        \n",
    "        # Saving training history\n",
    "        csv_logger = CSVLogger('training_B2_25ep.log', separator=',', append=False)\n",
    "        \n",
    "        # Defining the model parameter dict \n",
    "        keras_dict = {\n",
    "            'x': X_train,\n",
    "            'y': Y_train,\n",
    "            'batch_size': self.batch_size,\n",
    "            'epochs': self.epochs,\n",
    "            'shuffle': False,\n",
    "            'callbacks': [earlyStop, csv_logger]\n",
    "            #'callbacks': [csv_logger]\n",
    "\n",
    "        }\n",
    "\n",
    "        if self.train_test_split > 0:\n",
    "            keras_dict.update({\n",
    "                'validation_data': (X_val, Y_val)\n",
    "            })\n",
    "\n",
    "        # Fitting the model \n",
    "        model.fit(\n",
    "            **keras_dict\n",
    "        )\n",
    "\n",
    "        # Saving the model to the class \n",
    "        self.model = model\n",
    "        # Plotting train history\n",
    "        self.plot_train_history(model)\n",
    "        # Saving the model in json and h5\n",
    "        self.save_model(self.model)\n",
    "        \n",
    "        return model  \n",
    "\n",
    "    def predict(self) -> list:\n",
    "        \"\"\"\n",
    "        A method to predict using the test data used in creating the class\n",
    "        \"\"\"\n",
    "        yhat = []\n",
    "\n",
    "        if(self.train_test_split > 0):\n",
    "        \n",
    "            # Getting the last n time series \n",
    "            _, _, X_test, _, _, _ = self.create_data_for_NN()        \n",
    "\n",
    "            # Making the prediction list \n",
    "            yhat = [y[0] for y in self.model.predict(X_test)]\n",
    "\n",
    "        return yhat\n",
    "    \n",
    "    def plot_test(self):\n",
    "        yhat = self.predict()# Constructing the forecast dataframe\n",
    "        fc = self.data.tail(len(yhat)).copy()\n",
    "        fc['forecast'] = yhat\n",
    "        expected = fc.loc[:,'Valeur']\n",
    "        predictions = fc.loc[:,'forecast']\n",
    "        print('RMSE: %f [kWh]' % self.validation(predictions,expected, 'RMSE'))\n",
    "        print('MAPE: %f %%' % self.validation(predictions,expected, 'MAPE'))\n",
    "        # Ploting the forecasts\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for dtype in ['Valeur', 'forecast']:  \n",
    "            plt.plot(fc.index, fc[dtype],label=dtype,alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.gca().set(ylabel='Consumption [kWh]', xlabel='timestamp')\n",
    "        plt.yticks(fontsize=12, alpha=.7)\n",
    "        plt.title(\"Consumption in building 1 for test data\", fontsize=20)\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict_n_ahead(self, data_input, n_ahead: int):\n",
    "        dates = pd.date_range(data_input.index[-1], periods = n_ahead+1, freq='15T')[1:]\n",
    "        #data_input.index = pd.to_datetime(data_input.index)\n",
    "        test = data_input.append(pd.DataFrame(index=dates))\n",
    "        test.index=data_input.index.union(dates)\n",
    "        test = self.preprocess(test)\n",
    "        #print(test.columns.values)\n",
    "        y = test[self.Y_var].tolist()\n",
    "        #print(len(y))\n",
    "        y_holiday = test[self.holi_var].tolist()\n",
    "        #print(len(y_holiday))\n",
    "        y_hour_cos = test[self.hour_var_cos].tolist()\n",
    "        y_hour_sin = test[self.hour_var_sin].tolist()\n",
    "        y_weekday_cos = test[self.day_week_cos].tolist()\n",
    "        y_weekday_sin = test[self.day_week_sin].tolist()\n",
    "        y_month_cos = test[self.month_cos].tolist()\n",
    "        y_month_sin = test[self.month_sin].tolist()\n",
    "        y_minute_cos = test[self.minutes_cos].tolist()\n",
    "        y_minute_sin = test[self.minutes_sin].tolist()\n",
    "        yhat = []\n",
    "        X, _ = deep_learner.create_X_Y(y, y_holiday, y_hour_cos, y_hour_sin, y_weekday_cos, y_weekday_sin, y_month_cos, y_month_sin, y_minute_cos, y_minute_sin, self.lag, self.lag2)\n",
    "        #print(X.shape)\n",
    "        #print(self.model)\n",
    "        yhat = [y[0] for y in self.model.predict(X)]\n",
    "        return yhat[-n_ahead:]\n",
    "    \n",
    "    def evaluate_n_ahead(self, n_ahead: int):\n",
    "        self.data_user = pd.read_csv(self.import_file_path, index_col=0)\n",
    "        self.data_user.index = pd.to_datetime(self.data_user.index)\n",
    "        data_temp = self.data_user\n",
    "        #print(len(data_temp))\n",
    "        #print(data_temp.columns.values)\n",
    "        yhat = []\n",
    "        predictions = []\n",
    "        if hasattr('self', 'model') == False:\n",
    "            self.load_model()\n",
    "        for i in tf.range(n_ahead//96):\n",
    "            y_hat = self.predict_n_ahead(data_temp, self.lag)\n",
    "            #print(len(y_hat))\n",
    "            data_temp = data_temp.append(pd.DataFrame(y_hat, columns=['Valeur'], index=pd.date_range(data_temp.index[-1], periods = self.lag+1, freq='15T')[1:]))\n",
    "            #data_temp.resample('15T').interpolate('cubic')\n",
    "            data_temp.drop(data_temp.head(self.lag).index, inplace=True)\n",
    "            #print(len(data_temp))\n",
    "            #print(predictions)\n",
    "            #print(data_temp.columns.values)\n",
    "            predictions.extend(y_hat)\n",
    "        dates = pd.date_range(self.data_user.index[-1], periods = n_ahead, freq='15T')[1:]\n",
    "        #print(len(dates))\n",
    "        #print(len(predictions))\n",
    "        test = pd.DataFrame(predictions)\n",
    "        test.index = dates\n",
    "        test.index = pd.to_datetime(test.index)\n",
    "        test.to_csv(self.export_file_path, index=True)\n",
    "        expected = test_range.head(n_ahead).loc[:,\"Valeur\"]\n",
    "        predictions = test.iloc[:,0]\n",
    "        print('RMSE: %f [kWh]' % self.validation(predictions,expected, 'RMSE'))\n",
    "        print('MAPE: %f %%' % self.validation(predictions,expected, 'MAPE'))\n",
    "        plt.figure(figsize=(25, 10))\n",
    "        plt.grid()\n",
    "        plt.gca().set(ylabel='Consumption [kWh]', xlabel='timestamp')\n",
    "        plt.yticks(fontsize=12, alpha=.7)\n",
    "        plt.title(\"Consumption forecast in building 1 for given days ahead\", fontsize=20)\n",
    "        plt.plot(test_range.index, test_range.loc[:,\"Valeur\"], color='orange', label='test', alpha=0.7)\n",
    "        plt.plot(self.data_user.index, self.data_user.loc[:,\"Valeur\"], color='b', label='user input data', alpha=0.5)\n",
    "        plt.plot(test.index, test.iloc[:,0], color='black', linestyle='--', linewidth=3, label='Forecaster model',alpha=0.7)\n",
    "        plt.legend(prop={'size': 20})\n",
    "        plt.show()\n",
    "        #return test\n",
    "    \n",
    "    def configuration(self):\n",
    "        epilogue_usage = \"\"\"\n",
    "        Use cases examples:\n",
    "        Import the data './building1_input.csv' and use the preloaded model \"model_B!_complete\" to predict 672 steps ahead and save to './predictions.csv'\n",
    "        python forecast_lstm.py -F -i './building1_input.csv' -n 196 -e './predictions.csv' -M \"model_B!_complete\"\\n\n",
    "        Import the data './building1_input.csv' and predict 672 steps ahead and save to './predictions.csv'\n",
    "        python forecast_lstm.py -F -i './building1_input.csv' -n 196 -e './predictions.csv'\\n\n",
    "        Train the new model \"model_B!_new\" on the imported data './Consumption_15min.csv' with n steps for test\n",
    "        python forecast_lstm.py -T -i './Consumption_15min.csv' -M \"model_B!_new\" -t 10080\\n\n",
    "     \n",
    "        \"\"\"\n",
    "        parser = argparse.ArgumentParser(description='Make energy consumption forecasts and . Read the example to understand how it works', epilog= epilogue_usage,formatter_class=RawTextHelpFormatter)\n",
    "\n",
    "        parser.add_argument('-F', '--forecast', action='store_true',  help='Download data from copernicus database', default=False)\n",
    "        parser.add_argument('-T', '--train',  action='store_true', help='Format data from netcdf file to environment file', default=False)\n",
    "        parser.add_argument('-i', '--imp_dir', required=True, help='Import a timeseries')\n",
    "        parser.add_argument('-e', '--exp_dir', help='Export a forecasted timeseries')\n",
    "        parser.add_argument('-n', '--steps_ahead', help='Number of time steps to forecast')\n",
    "        parser.add_argument('-t', '--steps_test', help='Number of last time steps in the trainig set'\n",
    "                                                        'to keep for a test dataset')\n",
    "        parser.add_argument('-M', '--model', help='Name of model to save/load')\n",
    "\n",
    "\n",
    "        args = parser.parse_args()\n",
    "        #print(args)\n",
    "        \n",
    "        if args.forecast:\n",
    "            print('The imported csv is: ',args.imp_dir)\n",
    "            print('\\n')\n",
    "            print('Number of timesteps ahead to forecast is: ',args.steps_ahead)\n",
    "            print('\\n')\n",
    "            if args.model:\n",
    "                print('You decided to use a trained model:',args.model)\n",
    "                print('\\n')\n",
    "                self.model_load = args.model\n",
    "            self.import_file_path = args.imp_dir\n",
    "            self.export_file_path = args.exp_dir\n",
    "            self.evaluate_n_ahead(int(args.steps_ahead))\n",
    "            print('The forecasted timeseries is exported to',args.exp_dir)\n",
    "            #return test\n",
    "            \n",
    "        # TRAIN\n",
    "        if args.train:\n",
    "            print('The imported csv is: ',args.imp_dir)\n",
    "            print('\\n')\n",
    "            print('You decided to train a new model',args.model)\n",
    "            print('\\n')\n",
    "            self.model = deep_learner.LSTModel()\n",
    "            print('Number of timesteps to use in a test dataset: ',args.steps_test)\n",
    "            print('\\n')\n",
    "            self.plot_test()\n",
    "\n",
    "\n",
    "        print('\\n')\n",
    "        print('The end')\n",
    "        print('\\n')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    deep_learner = DeepModelTS(\n",
    "    # USER INPUT SETTINGS\n",
    "    Y_var = 'Valeur',\n",
    "    model_load = \"model_B!_complete\",\n",
    "    import_file_path = './building1_input.csv',\n",
    "    export_file_path = './predictions.csv',\n",
    "    # TRAINING SETTINGS\n",
    "    data_path = './Consumption_15min.csv',\n",
    "    #data = holidata,\n",
    "    model_save = \"model_B!_complete\",\n",
    "    lag = 96,\n",
    "    lag2 = 672,\n",
    "    LSTM_layer_depth = 50,\n",
    "    epochs = 200,\n",
    "    batch_size = 128,\n",
    "    train_test_split = 0.15,\n",
    "    n_test = 3360*2\n",
    "    )\n",
    "    deep_learner.configuration()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_learner = DeepModelTS(\n",
    "# USER INPUT SETTINGS\n",
    "Y_var = 'Valeur',\n",
    "model_load = \"model_B!_complete\",\n",
    "import_file_path = './building1_input.csv',\n",
    "export_file_path = './predictions.csv',\n",
    "# TRAINING SETTINGS\n",
    "data_path = './Consumption_15min.csv',\n",
    "#data = holidata,\n",
    "model_save = \"model_B!_complete\",\n",
    "lag = 96,\n",
    "lag2 = 672,\n",
    "LSTM_layer_depth = 50,\n",
    "epochs = 200,\n",
    "batch_size = 128,\n",
    "train_test_split = 0.15,\n",
    "n_test = 3360*2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.2951 - val_loss: 0.1077\n",
      "Epoch 2/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.1241 - val_loss: 0.0997\n",
      "Epoch 3/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.1161 - val_loss: 0.0967\n",
      "Epoch 4/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.1097 - val_loss: 0.0921\n",
      "Epoch 5/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.1049 - val_loss: 0.0886\n",
      "Epoch 6/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.1015 - val_loss: 0.0866\n",
      "Epoch 7/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0990 - val_loss: 0.0854\n",
      "Epoch 8/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0972 - val_loss: 0.0846\n",
      "Epoch 9/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0959 - val_loss: 0.0841\n",
      "Epoch 10/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0949 - val_loss: 0.0838\n",
      "Epoch 11/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0942 - val_loss: 0.0837\n",
      "Epoch 12/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0936 - val_loss: 0.0835\n",
      "Epoch 13/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0930 - val_loss: 0.0834\n",
      "Epoch 14/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0926 - val_loss: 0.0832\n",
      "Epoch 15/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0922 - val_loss: 0.0830\n",
      "Epoch 16/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0918 - val_loss: 0.0827\n",
      "Epoch 17/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0915 - val_loss: 0.0824\n",
      "Epoch 18/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0911 - val_loss: 0.0821\n",
      "Epoch 19/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0908 - val_loss: 0.0818\n",
      "Epoch 20/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0905 - val_loss: 0.0816\n",
      "Epoch 21/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0902 - val_loss: 0.0814\n",
      "Epoch 22/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0900 - val_loss: 0.0812\n",
      "Epoch 23/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0897 - val_loss: 0.0810\n",
      "Epoch 24/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0895 - val_loss: 0.0809\n",
      "Epoch 25/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0893 - val_loss: 0.0807\n",
      "Epoch 26/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0890 - val_loss: 0.0806\n",
      "Epoch 27/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0889 - val_loss: 0.0804\n",
      "Epoch 28/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0887 - val_loss: 0.0804\n",
      "Epoch 29/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0885 - val_loss: 0.0802\n",
      "Epoch 30/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0883 - val_loss: 0.0801\n",
      "Epoch 31/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0882 - val_loss: 0.0800\n",
      "Epoch 32/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0880 - val_loss: 0.0799\n",
      "Epoch 33/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0879 - val_loss: 0.0798\n",
      "Epoch 34/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0878 - val_loss: 0.0797\n",
      "Epoch 35/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0877 - val_loss: 0.0797\n",
      "Epoch 36/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0876 - val_loss: 0.0796\n",
      "Epoch 37/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0875 - val_loss: 0.0795\n",
      "Epoch 38/200\n",
      "1185/1185 [==============================] - 4s 3ms/step - loss: 0.0874 - val_loss: 0.0794\n",
      "Epoch 39/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0873 - val_loss: 0.0793\n",
      "Epoch 40/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0872 - val_loss: 0.0793\n",
      "Epoch 41/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0871 - val_loss: 0.0792\n",
      "Epoch 42/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0870 - val_loss: 0.0791\n",
      "Epoch 43/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0869 - val_loss: 0.0791\n",
      "Epoch 44/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0868 - val_loss: 0.0790\n",
      "Epoch 45/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0868 - val_loss: 0.0789\n",
      "Epoch 46/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0867 - val_loss: 0.0789\n",
      "Epoch 47/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0866 - val_loss: 0.0788\n",
      "Epoch 48/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0866 - val_loss: 0.0788\n",
      "Epoch 49/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0865 - val_loss: 0.0787\n",
      "Epoch 50/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0864 - val_loss: 0.0787\n",
      "Epoch 51/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0863 - val_loss: 0.0786\n",
      "Epoch 52/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0863 - val_loss: 0.0786\n",
      "Epoch 53/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0862 - val_loss: 0.0786\n",
      "Epoch 54/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0862 - val_loss: 0.0785\n",
      "Epoch 55/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0861 - val_loss: 0.0785\n",
      "Epoch 56/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0860 - val_loss: 0.0785\n",
      "Epoch 57/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0860 - val_loss: 0.0785\n",
      "Epoch 58/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0859 - val_loss: 0.0785\n",
      "Epoch 59/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0859 - val_loss: 0.0785\n",
      "Epoch 60/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0858 - val_loss: 0.0785\n",
      "Epoch 61/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0857 - val_loss: 0.0785\n",
      "Epoch 62/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0857 - val_loss: 0.0786\n",
      "Epoch 63/200\n",
      "1185/1185 [==============================] - 4s 3ms/step - loss: 0.0856 - val_loss: 0.0786\n",
      "Epoch 64/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0856 - val_loss: 0.0787\n",
      "Epoch 65/200\n",
      "1185/1185 [==============================] - 3s 3ms/step - loss: 0.0855 - val_loss: 0.0787\n",
      "Epoch 00065: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model = deep_learner.LSTModel ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DeepModelTS' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-74b550d8640e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeep_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-1dfa9fcfac26>\u001b[0m in \u001b[0;36mplot_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Constructing the forecast dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'forecast'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1dfa9fcfac26>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# Making the prediction list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DeepModelTS' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "deep_learner.plot_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_B!_complete.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-139ee19bae9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeep_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_n_ahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m672\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-de82588fa6bd>\u001b[0m in \u001b[0;36mevaluate_n_ahead\u001b[0;34m(self, n_ahead)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'self'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ahead\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_n_ahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-de82588fa6bd>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# load json and create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_load\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mloaded_model_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_B!_complete.json'"
     ]
    }
   ],
   "source": [
    "deep_learner.test = deep_learner.evaluate_n_ahead(672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:evgeny] *",
   "language": "python",
   "name": "conda-env-evgeny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

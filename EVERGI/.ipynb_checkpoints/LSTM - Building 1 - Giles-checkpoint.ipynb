{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-434fa26ecf87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0margparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRawTextHelpFormatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/../data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "\n",
    "DATA_DIR = os.path.dirname(os.path.abspath(__file__)).replace(\"\\\\\", \"/\") + \"/../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-48231eb77099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mconfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-48231eb77099>\u001b[0m in \u001b[0;36mconfiguration\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mepilogue_usage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\" Complete example: python forecast.py -tt 96 -T 200,20 -N my_model -t 10 -f 2016/12/01 -e 0  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'The following arguments must be included. Read the example to understand how it works'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepilog\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mepilogue_usage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformatter_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawTextHelpFormatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     parser.add_argument('-tt', '--timesteps', required=True, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 14 14:25:44 2020\n",
    "\n",
    "@author: givkriek\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Do not modify this def ! Unless you are an expert ;) \n",
    "def forecaster(cons, temp, steps, days, case, name):\n",
    "    '''\n",
    "    Forecaster is based on: https://web.archive.org/web/20200319010116if_/https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "    '''\n",
    "        \n",
    "    # Import dataset in numpy format\n",
    "    df = pd.read_csv(cons)\n",
    "    try:\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "    except ValueError:\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format=\"%d/%m/%Y %H:%M\")\n",
    "    df_cons = df.to_numpy()\n",
    "    \n",
    "    df = pd.read_csv(temp)\n",
    "    try:\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "    except ValueError:\n",
    "        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], format=\"%d/%m/%Y %H:%M\")\n",
    "    df_temp = df.to_numpy()\n",
    "    \n",
    "    # Inputs for neural network  \n",
    "    dataset = np.zeros((len(df_cons),6))\n",
    "    for timestep in range(len(df_cons)): \n",
    "        # Parameter to forecast\n",
    "        dataset[timestep,0] = df_cons[timestep][1]\n",
    "        # Input\n",
    "        dataset[timestep,1] = df_cons[timestep][0].weekday()\n",
    "        if df_cons[timestep][0].weekday() <= 4 : \n",
    "            dataset[timestep,2] = 0\n",
    "        else :\n",
    "            dataset[timestep,2] = 1\n",
    "        hour = df_cons[timestep][0].hour\n",
    "        minu = df_cons[timestep][0].minute\n",
    "        dataset[timestep,3] = int(hour*4+minu/15)\n",
    "        dataset[timestep,4] = df_cons[timestep][0].month\n",
    "        dataset[timestep,5] = df_temp[timestep][1]\n",
    "\n",
    "    pos=0\n",
    "    # Scale values by subtracting the mean and dividing by the standard deviation\n",
    "    data_mean = dataset.mean(axis=0)\n",
    "    data_std = dataset.std(axis=0)\n",
    "    dataset = (dataset-data_mean)/data_std      \n",
    "    \n",
    "    if steps[1] == 1: end = len(dataset)\n",
    "    else: end = len(dataset) - steps[1]\n",
    "\n",
    "    def multivariate_data(dataset, pos, start_index, end_index, history_size,\n",
    "                          target_size, step):\n",
    "        '''\n",
    "        Divide data in two groups, shifted \n",
    "        '''\n",
    "        # Inizialize lists\n",
    "        input_data = []\n",
    "        output_data = []\n",
    "        \n",
    "        # Start seperate data\n",
    "        start_index = start_index #+ history_size\n",
    "        for i in range(start_index, end_index):\n",
    "            input_data.append(dataset[range(i-history_size, i, step)])\n",
    "            output_data.append(dataset[:, pos][i:i+target_size])\n",
    "        \n",
    "        return np.array(input_data), np.array(output_data)\n",
    "\n",
    "    # Split data\n",
    "    for i in range(len(df_cons)):\n",
    "        if df_cons[i][0] == days[3]:\n",
    "            index = i\n",
    "\n",
    "    x_train, y_train = multivariate_data(dataset,pos, \n",
    "                                         0, days[0]*steps[0], \n",
    "                                         steps[0], steps[1], steps[2])\n",
    "    x_val, y_val = multivariate_data(dataset, pos,\n",
    "                                     days[0]*steps[0], (days[0] + days[1])*steps[0],\n",
    "                                     steps[0], steps[1], steps[2])\n",
    "    x_test, y_test = multivariate_data(dataset, pos,\n",
    "                                       index, end, \n",
    "                                       steps[0], steps[1], steps[2])\n",
    "    \n",
    "    # Special parameters to tune data\n",
    "    BATCH_SIZE = 60 \n",
    "    BUFFER_SIZE = 10000 \n",
    "    \n",
    "    # Shuffle, batch and slice data\n",
    "    tf.keras.backend.set_floatx('float64')\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "    val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "        \n",
    "    def training(steps, train_data, val_data):\n",
    "        '''\n",
    "        The training of the neural network\n",
    "        '''\n",
    "        # Setting seed to ensure reproducibility. \n",
    "        tf.random.set_seed(3)  \n",
    "        \n",
    "        # Special parameters to tune training\n",
    "        EPOCHS = 10\n",
    "        hidden_layers = 20\n",
    "        STEPS = 100\n",
    "        OPTIMIZATION = 'mean_squared_error'  \n",
    "    \n",
    "        # Create model\n",
    "        model = tf.keras.models.Sequential()\n",
    "        # Create layers\n",
    "        model.add(tf.keras.layers.LSTM(hidden_layers))  # Set number of hidden layers\n",
    "        model.add(tf.keras.layers.Dense(steps[1], activation = 'elu'))  # Dense = number of output layers\n",
    "        # Set objective function\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.000764), loss = OPTIMIZATION)\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(train_data, \n",
    "                            epochs = EPOCHS,\n",
    "                            steps_per_epoch = STEPS, \n",
    "                            validation_data = val_data,\n",
    "                            validation_steps = STEPS) \n",
    "              \n",
    "        print('\\n')\n",
    "        print('Training is done')\n",
    "        print('\\n')\n",
    "        \n",
    "        return history, model\n",
    "\n",
    "    def save_model(model, name):\n",
    "        '''\n",
    "        Once the neural network is trained, and it is used for several simulations,\n",
    "        it possible to save the training, to avoid re-training every time\n",
    "        '''\n",
    "        model.save(name+\".h5\")\n",
    "        \n",
    "    def load_model(name):\n",
    "        '''\n",
    "        if model is saved somewhere, and user wants to get it back, he\n",
    "        should use this funtion\n",
    "        '''\n",
    "        model = tf.keras.models.load_model(name+\".h5\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def plot_train_history(history):\n",
    "        '''\n",
    "        Convergence plots to have an idea on how the training performs\n",
    "        '''\n",
    "        print('\\n')\n",
    "        print('Convergence plot is diplaying ... To continue -> close the graph')\n",
    "        print('\\n')\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        \n",
    "        epochs = range(len(loss))\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "        plt.title('Training and validation losses')\n",
    "        plt.legend()\n",
    "        plt.show()  \n",
    "    \n",
    "    def test_forecaster(data):\n",
    "        '''\n",
    "        Only use this function when neural network is trained\n",
    "        '''\n",
    "        print('\\n')\n",
    "        print('Neural network test starts !')\n",
    "        print('\\n')\n",
    "        true_future = np.array([])\n",
    "        predicted_future = np.array([])\n",
    "        \n",
    "        [days, steps, pos, model, x_test, y_test, data_std, data_mean] = data\n",
    "        days_to_test = days[2]\n",
    "        \n",
    "        for step in range(int(days_to_test*(steps[0]/steps[1]))):\n",
    "            y = (y_test[step*steps[1]:step*steps[1] + steps[1], pos] * data_std[pos]) + data_mean[pos]  \n",
    "            predict_future = (np.array(model.predict(x_test[step*steps[1]:step*steps[1] + steps[0]])[pos])* data_std[pos]) + data_mean[pos]\n",
    "            \n",
    "            true_future = np.append(true_future, y)\n",
    "            predicted_future = np.append(predicted_future, predict_future)\n",
    "            print('Day number',step,'has been predicted')\n",
    "        return [true_future, predicted_future]\n",
    "            \n",
    "                \n",
    "    def plot_results(results):\n",
    "        '''\n",
    "        Once the neural network is tested, this function plots the results\n",
    "        '''\n",
    "        the_real_demand = results[0]\n",
    "        the_forecasted_demand = results[1]\n",
    "        print('Plotting results ... To continue -> close the graph')\n",
    "        x = np.arange(len(the_real_demand))\n",
    "        plt.figure()\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Demand [kW]')\n",
    "        plt.step(x,the_real_demand, label='Real demand')\n",
    "        plt.step(x,the_forecasted_demand, label='Forecasted demand')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def validation(forecasted, real, parameter):\n",
    "        ''' \n",
    "        compute some important parameters to compare forecasting results\n",
    "        '''\n",
    "        value = 0\n",
    "        value_1 = 0\n",
    "        value_2 = 0\n",
    "        \n",
    "        if parameter == 'SMAPE':\n",
    "            for i in range(len(forecasted)):\n",
    "                if real[i] + forecasted[i] == 0:\n",
    "                    value += 0\n",
    "                else: \n",
    "                    value += ((abs(real[i] - forecasted[i])) / (real[i] + forecasted[i])) * 100\n",
    "            final_value = value / len(forecasted)  \n",
    "            \n",
    "        elif parameter == 'MAPE':\n",
    "            for i in range(len(forecasted)):\n",
    "                if real[i] == 0:\n",
    "                    value += 0\n",
    "                else: \n",
    "                    value += (abs(real[i] - forecasted[i]))/real[i]\n",
    "            final_value = value / len(forecasted) * 100\n",
    "            \n",
    "        elif parameter == 'RMSE':\n",
    "            for i in range(len(forecasted)):\n",
    "                value += (real[i] - forecasted[i]) ** 2\n",
    "            final_value = (value / len(forecasted)) ** (1 / 2) \n",
    "            \n",
    "        elif parameter == 'R':\n",
    "            for i in range(len(forecasted)):\n",
    "                value += (real[i] - np.mean(real)) * (forecasted[i] - np.mean(forecasted))\n",
    "                value_1 += (real[i] - np.mean(real)) ** 2\n",
    "                value_2 += (forecasted[i] - np.mean(forecasted)) ** 2\n",
    "    \n",
    "            if value_1 == 0 or value_2 == 0:\n",
    "                final_value = 100\n",
    "            else:\n",
    "                final_value = (value / ((value_1 ** (1 / 2)) * (value_2 ** (1 / 2))))*100\n",
    "            \n",
    "        return final_value\n",
    "\n",
    "        \n",
    "    def create_csv(days, initial_day):\n",
    "        '''\n",
    "        Receive info to export in csv\n",
    "        For now: Date, time and power\n",
    "        '''       \n",
    "\n",
    "        dates = []\n",
    "        for i in range(len(results[1])):\n",
    "            dates.append(initial_day)\n",
    "            initial_day += dt.timedelta(minutes=15)\n",
    "            \n",
    "        dataset = [dates,results[1]]\n",
    "        \n",
    "        with open('forecasted_demand.csv', 'w') as f:\n",
    "            f.write('Date,\"Forecasted consumption kW\"')\n",
    "            f.write(\"\\n\")\n",
    "            for i in range(len(dataset[0])):\n",
    "                f.write(str(dataset[0][i]) + ',' + str(dataset[1][i]))\n",
    "                f.write(\"\\n\")\n",
    "                \n",
    "    # Start process\n",
    "    if case[0]:\n",
    "        history, model = training(steps, train_data, val_data)\n",
    "        save_model(model, name)\n",
    "        plot_train_history(history)\n",
    "        \n",
    "    else:\n",
    "        model = load_model(name)\n",
    "    \n",
    "    \n",
    "    # Concatenate data\n",
    "    data = [days, steps, pos, model, x_test, y_test, data_std, data_mean] \n",
    "    # The actual forecasting\n",
    "    results = test_forecaster(data)\n",
    "    # Plot results\n",
    "    plot_results(results)\n",
    "    # Print score of forecaster (RMSE, etc)\n",
    "    validation(results[1],results[0], 'MAPE')\n",
    "    # Export to csv (located in results files)\n",
    "    if case[1]:\n",
    "        create_csv(days, days[-1])\n",
    "        \n",
    "    \n",
    "def configuration():\n",
    "    '''\n",
    "    configuration\n",
    "    '''\n",
    "    epilogue_usage = \"\"\" Complete example: python forecast.py -tt 96 -T 200,20 -N my_model -t 10 -f 2016/12/01 -e 0  \"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='The following arguments must be included. Read the example to understand how it works', epilog= epilogue_usage,formatter_class=RawTextHelpFormatter)\n",
    "    \n",
    "    parser.add_argument('-tt', '--timesteps', required=True, \n",
    "                        help='How many timesteps to forecast ? Day-ahead=96, 12h-ahead=48, etc', default=False)\n",
    "    parser.add_argument('-T', '--training', required=True, \n",
    "                        help='Train neural network? NO ? enter 0. YES ? Enter number of days to train and validate with a coma to differentiate (e.g. 200,10)', default=False)\n",
    "    parser.add_argument('-N', '--name', required=True, \n",
    "                        help='Name your neural network to train or to load', default=False)\n",
    "    parser.add_argument('-t', '--test', required=True, \n",
    "                        help='Give the number of days to test', default=False)\n",
    "    parser.add_argument('-f', '--first_day', required=True, \n",
    "                        help='Give first day to test in format:  yyyy/mm/dd', default=False)\n",
    "    parser.add_argument('-e', '--export', required=True, \n",
    "                        help='Save test results? Yes, write 1, no then write 0', default=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Number of timesteps to forecast is: ',args.timesteps)\n",
    "    print('\\n')\n",
    "    # TRAIN\n",
    "    if len(args.training) > 0:\n",
    "        pos = args.training.find(',')\n",
    "        days = [int(args.training[:pos]), int(args.training[pos+1:])]\n",
    "        case = [True]\n",
    "        print('You decided to train a neural network with',days[0],'days and to validate it with',days[1],'days')\n",
    "        print('The neural network will be trained and saved under the name :',args.name)\n",
    "        \n",
    "    else: \n",
    "        case = [False]\n",
    "        print('You decided to use a trained neural network under name of:',args.name)\n",
    "    \n",
    "    # Name of neural network\n",
    "    name = args.name\n",
    "    \n",
    "    # TEST\n",
    "    days.append(int(args.test))\n",
    "    days.append(dt.datetime.strptime(args.first_day,\"%Y/%m/%d\"))\n",
    "    print('\\n')\n",
    "    print('The number of days to test is:', str(days[2]), 'with as first day to test:',str(days[3]))\n",
    "    print('\\n')\n",
    "    if case[0] : \n",
    "        print('Training starts !')\n",
    "        print('\\n')\n",
    "\n",
    "    # Export results in csv format ?\n",
    "    if int(args.export): case.append(True)\n",
    "    else: case.append(False)\n",
    "        \n",
    "    # Find path with data info\n",
    "    DATA_DIR = os.path.dirname(os.path.abspath(__file__)) + \"/../../data/\"   \n",
    "    cons = DATA_DIR+'dieteren_case/environment/Consumption_15min.csv'\n",
    "    temp = DATA_DIR+'dieteren_case/environment/Temp_15min.csv'\n",
    "    \n",
    "    # Configuration\n",
    "    steps = [96,int(args.timesteps),1]\n",
    "    \n",
    "    forecaster(cons, temp, steps, days, case, name)\n",
    "    \n",
    "    print('\\n')\n",
    "    print('The end')\n",
    "    print('\\n')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    configuration()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:evgeny]",
   "language": "python",
   "name": "conda-env-evgeny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

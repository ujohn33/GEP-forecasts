{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recreational-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input, Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import src.preprocessing_3days\n",
    "from src.preprocessing_3days import series_to_supervised, preprocess\n",
    "from src.functions import load_data, TimeSeriesTensor, create_evaluation_df, plot_train_history, validation, save_model, load_model\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ahead-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, n_test):\n",
    "    if len(df) < 8760:\n",
    "        n_test = round(len(df) * 0.2)\n",
    "    test_df = df.copy()[-(n_test+71):]\n",
    "    train_df = df.copy()[:-(len(test_df)-71)]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parallel-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIMO_fulldata_preparation(df, n_test=4380, T=72, HORIZON=72):\n",
    "    df = df.merge(series_to_supervised(df), how='right', left_index=True, right_index=True)\n",
    "    df = preprocess(df, 'Belgium')\n",
    "    train_df, test_df = train_test_split(df, n_test)\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaler.fit(train_df[['value']])\n",
    "    long_scaler = MinMaxScaler()\n",
    "    test_df[test_df.columns] = long_scaler.fit_transform(test_df)\n",
    "    train_df[train_df.columns] = long_scaler.fit_transform(train_df)\n",
    "    print(train_df.columns)\n",
    "    tensor_structure = {'X':(range(-T+1, 1), train_df.columns[:1]), 'X2':(range(1, 73), train_df.columns[1:6]), 'static':(None, train_df.columns[6:])}\n",
    "    #tensor_structure = {'X':(range(-24+1, 1), train_df.columns[:1]), 'X2':(range(-168+1, -96+1), train_df.columns[:1]), 'static':(None, train_df.columns[3:])}\n",
    "    #tensor_structure = {'X':(range(-T+1, 1), train_df.columns)}\n",
    "    #print(tensor_structure[0])\n",
    "    train_inputs = TimeSeriesTensor(train_df, 'value', HORIZON, tensor_structure)\n",
    "    test_inputs = TimeSeriesTensor(test_df, 'value', HORIZON, tensor_structure)\n",
    "    return train_inputs, test_inputs, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stylish-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEP1 = pd.read_csv('../data/GEP/Consumption_1H.csv', index_col=0, header=0, names=['value'])\n",
    "GEP4 = pd.read_csv('../data/GEP/B4_Consumption_1H.csv', index_col=0, header=0, names=['value'])\n",
    "datasets = [GEP1, GEP4]\n",
    "names = ['GEP1', 'GEP4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "breeding-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, test_inputs, y_scaler = MIMO_fulldata_preparation(GEP4, n_test=4380, T=72, HORIZON=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-today",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 100\n",
    "BATCHSIZE = 32\n",
    "patience = 10\n",
    "HORIZON = 72\n",
    "n_cell_lstm = 32\n",
    "\n",
    "# Add static input via functional api\n",
    "dynamic_input = Input(shape=[HORIZON, 6], name='time-series')\n",
    "static_input = Input(shape=[8], name='one-hot')\n",
    "\n",
    "static_out = (static_input)\n",
    "x = tf.keras.layers.LSTM(n_cell_lstm, return_sequences=True)(dynamic_input)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "dynamic_out = (x)\n",
    "z = tf.keras.layers.concatenate([dynamic_out, static_out])\n",
    "z = tf.keras.layers.Dense(HORIZON, activation='relu')(z)\n",
    "main_output = tf.keras.layers.Dense(HORIZON, activation='softmax', name='main_output')(z)\n",
    "\n",
    "FULL_LSTMIMO = Model(inputs=[dynamic_input, static_input], outputs=[z])\n",
    "\n",
    "\n",
    "metrics = pd.DataFrame(columns=['mae','mape', 'rmse', 'B'], index=range(28))\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "dX_train = []\n",
    "dstatic_train = []\n",
    "dT_train = []\n",
    "dX_test = []\n",
    "dstatic_test = []\n",
    "dX_scaler = []\n",
    "for i,df in enumerate(datasets):\n",
    "    train_inputs, test_inputs, y_scaler = MIMO_fulldata_preparation(df, n_test=4380, T=72, HORIZON=72)\n",
    "    concat_input = tf.concat([train_inputs['X'],train_inputs['X2']], axis=2)\n",
    "    dX_train.append(concat_input)\n",
    "    dstatic_train.append(train_inputs['static'])\n",
    "    dT_train.append(train_inputs['target'])\n",
    "    dX_test.append(test_inputs)\n",
    "    dstatic_test.append(test_inputs['static'])\n",
    "    dX_scaler.append(y_scaler)\n",
    "global_inputs_X = tf.concat(dX_train, 0)\n",
    "global_inputs_static = tf.concat(dstatic_train, 0)\n",
    "global_inputs_T = tf.concat(dT_train, 0)\n",
    "#test_inputs = pd.concat(dn_test, axis=1)\n",
    "\n",
    "# full data LSTM MIMO compilation and fit\n",
    "FULL_LSTMIMO.compile(optimizer=tf.optimizers.Adam(), loss='mse', metrics=[tf.metrics.MeanSquaredError()])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "        \n",
    "history = FULL_LSTMIMO.fit([global_inputs_X, global_inputs_static], global_inputs_T, batch_size=1500, epochs=MAX_EPOCHS,\n",
    "                      validation_split=0.15,\n",
    "                      callbacks=[early_stopping], verbose=1)\n",
    "save_model(FULL_LSTMIMO, 'new_inputs_model')\n",
    "for i,df in enumerate(datasets):\n",
    "    concat_input = tf.concat([dX_test[i]['X'],dX_test[i]['X2']], axis=2)\n",
    "    FD_predictions = FULL_LSTMIMO.predict([concat_input, dstatic_test[i]])\n",
    "    FD_eval_df = create_evaluation_df(FD_predictions, dX_test[i], HORIZON, dX_scaler[i])\n",
    "    mae = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'MAE')\n",
    "    mape = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'MAPE')\n",
    "    rmse = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'RMSE')\n",
    "    #print('rmse {}'.format(rmse))\n",
    "    metrics.loc[i] = pd.Series({'mae':mae, 'mape':mape, 'rmse':rmse, 'B': names[i]})\n",
    "metrics.to_csv('./results/GEP/global/3days/24h_LSTM.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

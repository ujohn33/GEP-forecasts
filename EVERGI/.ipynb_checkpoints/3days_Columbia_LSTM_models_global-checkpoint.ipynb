{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input, Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import src.preprocessing_3days\n",
    "from src.preprocessing_3days import series_to_supervised, preprocess\n",
    "from src.functions import load_data, TimeSeriesTensor, create_evaluation_df, plot_train_history, validation, save_model, load_model\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grand-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, n_test):\n",
    "    if len(df) < 8760:\n",
    "        n_test = round(len(df) * 0.2)\n",
    "    test_df = df.copy()[-(n_test+71):]\n",
    "    train_df = df.copy()[:-(len(test_df)-71)]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capable-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIMO_fulldata_preparation(df, n_test=4380, T=72, HORIZON=72):\n",
    "    df = df.merge(series_to_supervised(df), how='right', left_index=True, right_index=True)\n",
    "    df = preprocess(df, 'Belgium')\n",
    "    train_df, test_df = train_test_split(df, n_test)\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaler.fit(train_df[['value']])\n",
    "    long_scaler = MinMaxScaler()\n",
    "    test_df[test_df.columns] = long_scaler.fit_transform(test_df)\n",
    "    train_df[train_df.columns] = long_scaler.fit_transform(train_df)\n",
    "    #print(train_df.columns)\n",
    "    #tensor_structure = {'X':(range(-T+1, 1), train_df.columns[:1]), 'X2':(range(1, 73), train_df.columns[1:6]), 'static':(None, train_df.columns[6:])}\n",
    "    tensor_structure = {'X':(range(-T+1, 1), train_df.columns[:1]), 'X2':(range(1, 73), train_df.columns[1:])}\n",
    "    #tensor_structure = {'X':(range(-T+1, 1), train_df.columns)}\n",
    "    #print(tensor_structure[0])\n",
    "    train_inputs = TimeSeriesTensor(train_df, 'value', HORIZON, tensor_structure)\n",
    "    test_inputs = TimeSeriesTensor(test_df, 'value', HORIZON, tensor_structure)\n",
    "    return train_inputs, test_inputs, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "expanded-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "clear-translation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "metrics = pd.DataFrame(columns=['mae','mape', 'rmse', 'B'], index=range(28))\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "dX_train = []\n",
    "dX_test = []\n",
    "dX_scaler = []\n",
    "for i in pbar(range(1,28)):\n",
    "    filename = '../data/Columbia_clean/Residential_'+str(i)+'.csv'\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    train_inputs, test_inputs, y_scaler = MIMO_fulldata_preparation(df)\n",
    "    baseline = Baseline(label_index = 0)\n",
    "    baseline.compile(loss=tf.losses.MeanSquaredError(), metrics=[tf.metrics.MeanSquaredError()])\n",
    "    predictions_B = baseline.predict(test_inputs['X'])\n",
    "    eval_df_B = create_evaluation_df(predictions_B.reshape(-1,24), test_inputs, 24, y_scaler)\n",
    "    mape = validation(eval_df_B['prediction'], eval_df_B['actual'], 'MAPE')\n",
    "    mae = validation(eval_df_B['prediction'], eval_df_B['actual'], 'MAE')\n",
    "    rmse = validation(eval_df_B['prediction'], eval_df_B['actual'], 'RMSE')\n",
    "    metrics.loc[i-1] = pd.Series({'mae':mae, 'mape':mape, 'rmse':rmse, 'B': i})\n",
    "metrics.to_csv('./results/Columbia/global/baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "temporal-singapore",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420321 samples, validate on 74175 samples\n",
      "Epoch 1/100\n",
      "328500/420321 [======================>.......] - ETA: 1:32 - loss: 0.0129 - mean_squared_error: 0.0129WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mean_squared_error\n",
      "328500/420321 [======================>.......] - ETA: 1:32 - loss: 0.0129 - mean_squared_error: 0.0129"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5e605191e5b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m history = FULL_LSTMIMO.fit(global_inputs_X, global_inputs_T, batch_size=1500, epochs=MAX_EPOCHS,\n\u001b[1;32m     42\u001b[0m                       \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                       callbacks=[early_stopping], verbose=1)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFULL_LSTMIMO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Columbia_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 100\n",
    "BATCHSIZE = 32\n",
    "patience = 10\n",
    "HORIZON = 72\n",
    "\n",
    "\n",
    "FULL_LSTMIMO = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, input_shape=(HORIZON, 14)),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(HORIZON)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics = pd.DataFrame(columns=['mae','mape', 'rmse', 'B'], index=range(28))\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "dX_train = []\n",
    "dT_train = []\n",
    "dX_test = []\n",
    "dX_scaler = []\n",
    "for i in pbar(range(1,29)):\n",
    "    filename = '../data/Columbia_clean/Residential_'+str(i)+'.csv'\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    train_inputs, test_inputs, y_scaler = MIMO_fulldata_preparation(df, n_test=4380, T=72, HORIZON=72)\n",
    "    dX_train.append(tf.concat([train_inputs['X'],train_inputs['X2']], axis=2))\n",
    "    dT_train.append(train_inputs['target'])\n",
    "    dX_test.append(test_inputs)\n",
    "    dX_scaler.append(y_scaler)\n",
    "global_inputs_X = tf.concat(dX_train, 0)\n",
    "global_inputs_T = tf.concat(dT_train, 0)\n",
    "#test_inputs = pd.concat(dn_test, axis=1)\n",
    "\n",
    "# full data LSTM MIMO compilation and fit\n",
    "FULL_LSTMIMO.compile(optimizer=tf.optimizers.Adam(), loss='mse', metrics=[tf.metrics.MeanSquaredError()])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "        \n",
    "history = FULL_LSTMIMO.fit(global_inputs_X, global_inputs_T, batch_size=1500, epochs=MAX_EPOCHS,\n",
    "                      validation_split=0.15,\n",
    "                      callbacks=[early_stopping], verbose=1)\n",
    "save_model(FULL_LSTMIMO, 'Columbia_model')\n",
    "\n",
    "for i in range(0,28):\n",
    "    concat_input = tf.concat([dX_test[i]['X'],dX_test[i]['X2']], axis=2)\n",
    "    FD_predictions = FULL_LSTMIMO.predict(concat_input)\n",
    "    FD_eval_df = create_evaluation_df(FD_predictions, dX_test[i], HORIZON, dX_scaler[i])\n",
    "    mae = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'MAE')\n",
    "    mape = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'MAPE')\n",
    "    rmse = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'RMSE')\n",
    "    #print('rmse {}'.format(rmse))\n",
    "    metrics.loc[i] = pd.Series({'mae':mae, 'mape':mape, 'rmse':rmse, 'B': names[i]})\n",
    "metrics.to_csv('./results/Columbia/global/3days/revised2_LSTM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "saved-landing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:748 train_step\n        loss = self.compiled_loss(\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1195 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10398 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3477 _create_op_internal\n        ret = Operation(\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 72 and 24 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_1/dense_1/BiasAdd, Cast)' with input shapes: [?,72], [?,24].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ce1f91cfbbe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m history = FULL_LSTMIMO.fit(global_inputs_X, global_inputs_T, batch_size=32, epochs=MAX_EPOCHS,\n\u001b[0m\u001b[1;32m     48\u001b[0m                       \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                       callbacks=[early_stopping], verbose=1)\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:748 train_step\n        loss = self.compiled_loss(\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1195 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10398 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3477 _create_op_internal\n        ret = Operation(\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/ubuntu/anaconda3/envs/evgeny/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 72 and 24 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_1/dense_1/BiasAdd, Cast)' with input shapes: [?,72], [?,24].\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 100\n",
    "BATCHSIZE = 32\n",
    "patience = 10\n",
    "HORIZON = 72\n",
    "\n",
    "#FULL_LSTMIMO = tf.keras.models.Sequential([\n",
    "#    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "#    tf.keras.layers.LSTM(32, input_shape=(24, 15)),\n",
    "#    # Shape => [batch, time, features]\n",
    "#    tf.keras.layers.Dense(HORIZON)\n",
    "#])\n",
    "\n",
    "FULL_LSTMIMO = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, input_shape=(24, 15), return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(HORIZON)\n",
    "])\n",
    "\n",
    "\n",
    "metrics = pd.DataFrame(columns=['mae','mape', 'rmse', 'B'], index=range(28))\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "dX_train = []\n",
    "dT_train = []\n",
    "dX_test = []\n",
    "dX_scaler = []\n",
    "for i in pbar(range(1,28)):\n",
    "    filename = '../data/Columbia_clean/Residential_'+str(i)+'.csv'\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    train_inputs, test_inputs, y_scaler = MIMO_fulldata_preparation(df)\n",
    "    dX_train.append(train_inputs['X'])\n",
    "    dT_train.append(train_inputs['target'])\n",
    "    dX_test.append(test_inputs)\n",
    "    dX_scaler.append(y_scaler)\n",
    "global_inputs_X = tf.concat(dX_train, 0)\n",
    "global_inputs_T = tf.concat(dT_train, 0)\n",
    "#test_inputs = pd.concat(dn_test, axis=1)\n",
    "\n",
    "# full data LSTM MIMO compilation and fit\n",
    "FULL_LSTMIMO.compile(optimizer=tf.optimizers.Adam(), loss='mse', metrics=[tf.metrics.MeanSquaredError()])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "        \n",
    "history = FULL_LSTMIMO.fit(global_inputs_X, global_inputs_T, batch_size=32, epochs=MAX_EPOCHS,\n",
    "                      validation_split=0.15,\n",
    "                      callbacks=[early_stopping], verbose=1)\n",
    "for i in range(1,28):\n",
    "    FD_predictions = FULL_LSTMIMO.predict(dX_test[i-1]['X'])\n",
    "    FD_eval_df = create_evaluation_df(FD_predictions, dX_test[i-1], HORIZON, dX_scaler[i-1])\n",
    "    mae = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'MAE')\n",
    "    mape = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'MAPE')\n",
    "    rmse = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'RMSE')\n",
    "    #print('rmse {}'.format(rmse))\n",
    "    metrics.loc[i-1] = pd.Series({'mae':mae, 'mape':mape, 'rmse':rmse, 'B': i})\n",
    "metrics.to_csv('./results/Columbia/global/3days/stacked_LSTM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "green-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 24, 5) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 8) dtype=float64>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 2) dtype=float64>)\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layer dense_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer rnn_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 24, 5) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 8) dtype=float64>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 2) dtype=float64>)\n",
      "Consider rewriting this model with the Functional API.\n",
      "12675/12676 [============================>.] - ETA: 0s - loss: 0.0070 - mean_squared_error: 0.0070WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 24, 5) dtype=float64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 8) dtype=float64>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 2) dtype=float64>)\n",
      "Consider rewriting this model with the Functional API.\n",
      "12676/12676 [==============================] - 286s 23ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 2/100\n",
      "12676/12676 [==============================] - 287s 23ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 3/100\n",
      "12676/12676 [==============================] - 287s 23ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 4/100\n",
      "12676/12676 [==============================] - 282s 22ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 5/100\n",
      "12676/12676 [==============================] - 286s 23ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 6/100\n",
      "12676/12676 [==============================] - 289s 23ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 7/100\n",
      "12676/12676 [==============================] - 288s 23ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 8/100\n",
      "12676/12676 [==============================] - 269s 21ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 9/100\n",
      "12676/12676 [==============================] - 164s 13ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 10/100\n",
      "12676/12676 [==============================] - 168s 13ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 11/100\n",
      "12676/12676 [==============================] - 161s 13ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
      "Epoch 12/100\n",
      "12676/12676 [==============================] - 161s 13ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 13/100\n",
      "12676/12676 [==============================] - 160s 13ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
      "Epoch 14/100\n",
      "12676/12676 [==============================] - 161s 13ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 15/100\n",
      "12676/12676 [==============================] - 161s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 16/100\n",
      "12676/12676 [==============================] - 161s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 17/100\n",
      "12676/12676 [==============================] - 161s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 18/100\n",
      "12676/12676 [==============================] - 161s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 19/100\n",
      "12676/12676 [==============================] - 161s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 20/100\n",
      "12676/12676 [==============================] - 162s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 21/100\n",
      "12676/12676 [==============================] - 162s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 22/100\n",
      "12676/12676 [==============================] - 162s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 23/100\n",
      "12676/12676 [==============================] - 162s 13ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 24, 5) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 8) dtype=float64>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 2) dtype=float64>)\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 100\n",
    "BATCHSIZE = 32\n",
    "patience = 10\n",
    "HORIZON = 24\n",
    "\n",
    "#ConditionalRNN = tf.keras.models.Sequential([\n",
    "#    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "#    tf.keras.layers.LSTM(32, input_shape=(24, 15)),\n",
    "#    # Shape => [batch, time, features]\n",
    "#    tf.keras.layers.Dense(HORIZON)\n",
    "#])\n",
    "\n",
    "ConditionalRNN = Sequential(layers=[ConditionalRNN(32, cell='LSTM'),\n",
    "                                    Dense(HORIZON)])\n",
    "\n",
    "\n",
    "metrics = pd.DataFrame(columns=['mae','mape', 'rmse', 'B'], index=range(28))\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "dX_train = []\n",
    "dc1_train = []\n",
    "dc2_train = []\n",
    "dT_train = []\n",
    "dX_test = []\n",
    "dc1_test = []\n",
    "dc2_test = []\n",
    "dX_scaler = []\n",
    "for i in pbar(range(1,28)):\n",
    "    filename = '../data/Columbia_clean/Residential_'+str(i)+'.csv'\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    train_inputs, test_inputs, train_c1, test_c1, train_c2, test_c2, y_scaler = ConditionalRNN_data_preparation(df)\n",
    "    dX_train.append(train_inputs['X'])\n",
    "    dT_train.append(train_inputs['target'])\n",
    "    dc1_train.append(train_c1)\n",
    "    dc2_train.append(train_c2)\n",
    "    dc1_test.append(test_c1)\n",
    "    dc2_test.append(test_c2)\n",
    "    dX_test.append(test_inputs)\n",
    "    dX_scaler.append(y_scaler)\n",
    "global_inputs_X = tf.concat(dX_train, 0)\n",
    "global_inputs_c1 = tf.concat(dc1_train, 0)\n",
    "global_inputs_c2 = tf.concat(dc2_train, 0)\n",
    "global_inputs_T = tf.concat(dT_train, 0)\n",
    "#test_inputs = pd.concat(dn_test, axis=1)\n",
    "\n",
    "# full data LSTM MIMO compilation and fit\n",
    "ConditionalRNN.compile(optimizer=tf.optimizers.Adam(), loss='mse', metrics=[tf.metrics.MeanSquaredError()])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "        \n",
    "history = ConditionalRNN.fit([global_inputs_X, global_inputs_c1, global_inputs_c2], global_inputs_T, batch_size=32, epochs=MAX_EPOCHS,\n",
    "                      validation_split=0.15,\n",
    "                      callbacks=[early_stopping], verbose=1)\n",
    "for i in range(1,28):\n",
    "    FD_predictions = ConditionalRNN.predict([dX_test[i-1]['X'],dc1_test[i-1],dc2_test[i-1]])\n",
    "    FD_eval_df = create_evaluation_df(FD_predictions, dX_test[i-1], HORIZON, dX_scaler[i-1])\n",
    "    mae = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'MAE')\n",
    "    mape = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'MAPE')\n",
    "    rmse = validation(FD_eval_df['prediction'], FD_eval_df['actual'], 'RMSE')\n",
    "    #print('rmse {}'.format(rmse))\n",
    "    metrics.loc[i-1] = pd.Series({'mae':mae, 'mape':mape, 'rmse':rmse, 'B': i})\n",
    "metrics.to_csv('./results/Columbia/global/conditional_LSTM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "killing-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConditionalRNN_data_preparation(df, n_test=4380, T=24, HORIZON=24):\n",
    "    df = src.preprocessing.preprocess(df, 'Canada')\n",
    "    c2 = series_to_supervised(df)\n",
    "    c1 = df.iloc[:,1:9]\n",
    "    c1 = c1.loc[c2.index]\n",
    "    short_df = df.iloc[:,[0,1,-4,-3,-2,-1]].copy()\n",
    "    #check how to formulate more correctly\n",
    "    short_df = short_df[146:]\n",
    "    train_df, test_df = train_test_split(short_df, n_test)\n",
    "    train_c1, test_c1 = train_test_split(c1, n_test)\n",
    "    train_c2, test_c2 = train_test_split(c2, n_test)\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaler.fit(train_df[['value']])\n",
    "    train_c2[['value(t-24)']] = y_scaler.fit_transform(train_c2[['value(t-24)']])\n",
    "    train_c2[['value(t-168)']] = y_scaler.fit_transform(train_c2[['value(t-168)']])\n",
    "    X_scaler = MinMaxScaler()\n",
    "    train_df[train_df.columns] = X_scaler.fit_transform(train_df)\n",
    "    test_df[train_df.columns] = X_scaler.fit_transform(test_df)\n",
    "    tensor_structure = {'X':(range(-T+1, 1), ['value','fractional hour_sin','fractional hour_cos','day of year_sin','day of year_cos'])}\n",
    "    train_inputs = TimeSeriesTensor(train_df, 'value', HORIZON, tensor_structure)\n",
    "    test_inputs = TimeSeriesTensor(test_df, 'value', HORIZON, tensor_structure)\n",
    "    train_c1 = c1.reindex(train_inputs.dataframe.index)\n",
    "    train_c2 = c2.reindex(train_inputs.dataframe.index)\n",
    "    test_c1 = c1.reindex(test_inputs.dataframe.index)\n",
    "    test_c2 = c2.reindex(test_inputs.dataframe.index)\n",
    "    return train_inputs, test_inputs, train_c1, test_c1, train_c2, test_c2, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-trail",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-filename",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-reggae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

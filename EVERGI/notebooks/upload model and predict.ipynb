{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "# Import mlcompute module to use the optional set_mlc_device API for device selection with ML Compute.\n",
    "#from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "# Select CPU device.\n",
    "#mlcompute.set_mlc_device(device_name='any') # Available options are 'cpu', 'gpu', and 'any'.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import src.preprocessing_3days\n",
    "from src.preprocessing_3days import series_to_supervised, preprocess\n",
    "from src.functions import load_data, TimeSeriesTensor, create_evaluation_df, plot_train_history, validation, save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, n_test, horizon):\n",
    "    if len(df) < 8760:\n",
    "        n_test = round(len(df) * 0.2)\n",
    "    test_df = df.copy()[-(n_test+horizon-1):]\n",
    "    train_df = df.copy()[:-(len(test_df)-horizon+1)]\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def MIMO_fulldata_preparation(df, n_test=4380, T=72, HORIZON=72, country='Canada'):\n",
    "    df = df.merge(series_to_supervised(df), how='right', left_index=True, right_index=True)\n",
    "    df = preprocess(df, country)\n",
    "    train_df, test_df = train_test_split(df, n_test, horizon=HORIZON)\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaler.fit(train_df[['value']])    \n",
    "    long_scaler = MinMaxScaler()\n",
    "    train_df[train_df.columns] = long_scaler.fit_transform(train_df)\n",
    "    test_df[test_df.columns] = long_scaler.transform(test_df)\n",
    "    tensor_structure = {'X':(range(-T+1, 1), train_df.columns[:1]), 'X2':(range(1, HORIZON+1), train_df.columns[1:])}\n",
    "    train_inputs = TimeSeriesTensor(train_df, 'value', HORIZON, tensor_structure)\n",
    "    test_inputs = TimeSeriesTensor(test_df, 'value', HORIZON, tensor_structure)\n",
    "    return train_inputs, test_inputs, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(l, drop, n, lr):\n",
    "    if l==1:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.LSTM(n, input_shape=(HORIZON, 14)),\n",
    "            tf.keras.layers.Dense(HORIZON)\n",
    "        ])\n",
    "    elif l==2:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "            tf.keras.layers.LSTM(n, input_shape=(HORIZON, 14), return_sequences=True),\n",
    "            tf.keras.layers.Dropout(drop),\n",
    "            tf.keras.layers.LSTM(n),\n",
    "            # Shape => [batch, time, features]\n",
    "            tf.keras.layers.Dense(HORIZON)\n",
    "        ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer=opt,metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def format_output(df):\n",
    "    df['h'] = df['h'].str.extract('(\\d+)', expand=False).astype(int)\n",
    "    ppivot = pd.pivot_table(df, values='prediction', index=['timestamp'], columns=['h'])\n",
    "    ppivot = ppivot.add_prefix('h_')\n",
    "    ppivot.index = pd.to_datetime(ppivot.index)\n",
    "    apivot = pd.pivot_table(df, values='actual', index=['timestamp'], columns=['h'])\n",
    "    apivot = apivot.add_prefix('h_')\n",
    "    apivot.index = pd.to_datetime(ppivot.index)\n",
    "    return ppivot, apivot\n",
    "\n",
    "def flatten(data):\n",
    "    flat_list = []\n",
    "    # iterating over the data\n",
    "    for item in data:\n",
    "        # appending elements to the flat_list\n",
    "        flat_list += item\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "names = []\n",
    "for i in range(1,29):\n",
    "    filename = '../data/Columbia_clean/Residential_'+str(i)+'.csv'\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    datasets.append(df)\n",
    "    names.append('B'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "names = []\n",
    "hourly = pd.read_csv('../data/London_smart_meters/London_hourly_all.csv', index_col='tstp')\n",
    "for house in hourly['LCLid'].unique():\n",
    "    temp = hourly.loc[hourly['LCLid'] == house]\n",
    "    datasets.append(temp)\n",
    "    names.append(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "LSTMIMO = load_model('./models/London_models/global_skilled-frog-284')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_test = []\n",
    "dX_scaler = []\n",
    "HORIZON = 72\n",
    "country = 'UK'\n",
    "dset = 'London'\n",
    "run_name = 'scaled_life'\n",
    "metrics = pd.DataFrame(columns=['mae','mape', 'rmse', 'B'], index=range(28))\n",
    "for i,df in enumerate(datasets):\n",
    "        train_inputs, test_inputs, y_scaler = MIMO_fulldata_preparation(df, n_test=4380, T=HORIZON, HORIZON=HORIZON, country=country)\n",
    "        dX_test.append(test_inputs)\n",
    "        dX_scaler.append(y_scaler)\n",
    "        concat_input = tf.concat([dX_test[i]['X'],dX_test[i]['X2']], axis=2)\n",
    "        FD_predictions = LSTMIMO.predict(concat_input)\n",
    "        FD_eval_df = create_evaluation_df(FD_predictions, dX_test[i], HORIZON, dX_scaler[i])\n",
    "        preds, actuals = format_output(FD_eval_df)\n",
    "        preds = preds[np.where(preds.index.hour == 0)[0][0]:][::24]\n",
    "        actuals = actuals[np.where(actuals.index.hour == 0)[0][0]:][::24]\n",
    "        full = actuals.merge(preds, how='inner', left_index=True, right_index=True, suffixes=('_actuals', '_preds'))\n",
    "        #full.to_csv('./results/'+dset+'/'+wandb.run.name+'_'+str(i)+'.csv')\n",
    "        preds = flatten(preds.values.tolist())\n",
    "        actuals = flatten(actuals.values.tolist())\n",
    "        mae = validation(preds, actuals, 'MAE')\n",
    "        mape = validation(preds, actuals, 'MAPE')\n",
    "        rmse = validation(preds, actuals, 'RMSE')\n",
    "        #print('rmse {}'.format(rmse))\n",
    "        metrics.loc[i] = pd.Series({'mae':mae, 'mape':mape, 'rmse':rmse, 'B': names[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131583</td>\n",
       "      <td>47.6225</td>\n",
       "      <td>0.22736</td>\n",
       "      <td>MAC000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0905566</td>\n",
       "      <td>67.3195</td>\n",
       "      <td>0.168249</td>\n",
       "      <td>MAC001814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0809991</td>\n",
       "      <td>74.1025</td>\n",
       "      <td>0.113524</td>\n",
       "      <td>MAC003721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148538</td>\n",
       "      <td>40.9636</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>MAC003341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048963</td>\n",
       "      <td>63.947</td>\n",
       "      <td>0.0722627</td>\n",
       "      <td>MAC001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.112996</td>\n",
       "      <td>79.8493</td>\n",
       "      <td>0.256048</td>\n",
       "      <td>MAC003618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.283427</td>\n",
       "      <td>61.4328</td>\n",
       "      <td>0.469732</td>\n",
       "      <td>MAC001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.326917</td>\n",
       "      <td>85.0468</td>\n",
       "      <td>0.501918</td>\n",
       "      <td>MAC003622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.27822</td>\n",
       "      <td>65.4824</td>\n",
       "      <td>0.407986</td>\n",
       "      <td>MAC002385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.211333</td>\n",
       "      <td>72.4751</td>\n",
       "      <td>0.412336</td>\n",
       "      <td>MAC002195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mae     mape       rmse          B\n",
       "0    0.131583  47.6225    0.22736  MAC000020\n",
       "1   0.0905566  67.3195   0.168249  MAC001814\n",
       "2   0.0809991  74.1025   0.113524  MAC003721\n",
       "3    0.148538  40.9636   0.246479  MAC003341\n",
       "4    0.048963   63.947  0.0722627  MAC001688\n",
       "..        ...      ...        ...        ...\n",
       "85   0.112996  79.8493   0.256048  MAC003618\n",
       "86   0.283427  61.4328   0.469732  MAC001611\n",
       "87   0.326917  85.0468   0.501918  MAC003622\n",
       "88    0.27822  65.4824   0.407986  MAC002385\n",
       "89   0.211333  72.4751   0.412336  MAC002195\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HORIZON == 72:\n",
    "    metrics.to_csv('./results/'+dset+'/global/3days/LSTM_'+run_name+'.csv')\n",
    "if HORIZON == 24:\n",
    "    metrics.to_csv('./results/'+dset+'/global/dayahead/LSTM_'+run_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3270023862973313\n"
     ]
    }
   ],
   "source": [
    "print(metrics['rmse'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.50297365607194\n"
     ]
    }
   ],
   "source": [
    "print(metrics['mape'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "# Import mlcompute module to use the optional set_mlc_device API for device selection with ML Compute.\n",
    "#from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "# Select CPU device.\n",
    "#mlcompute.set_mlc_device(device_name='any') # Available options are 'cpu', 'gpu', and 'any'.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import src.preprocessing_3days\n",
    "from src.preprocessing_3days import series_to_supervised, preprocess\n",
    "from src.functions import load_data, TimeSeriesTensor, create_evaluation_df, plot_train_history, validation, save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, n_test, horizon):\n",
    "    if len(df) < 8760:\n",
    "        n_test = round(len(df) * 0.2)\n",
    "    test_df = df.copy()[-(n_test+horizon-1):]\n",
    "    train_df = df.copy()[:-(len(test_df)-horizon+1)]\n",
    "    return train_df, test_df\n",
    "\n",
    "def MIMO_fulldata_preparation(df, n_test=4380, T=72, HORIZON=72, country='Canada'):\n",
    "    df = df.merge(series_to_supervised(df), how='right', left_index=True, right_index=True)\n",
    "    df = preprocess(df, country)\n",
    "    train_df, test_df = train_test_split(df, n_test, horizon=HORIZON)\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaler.fit(df[['value']])\n",
    "    long_scaler = MinMaxScaler()\n",
    "    print(test_df.columns)\n",
    "    test_df[test_df.columns] = long_scaler.fit_transform(test_df)\n",
    "    train_df[train_df.columns] = long_scaler.fit_transform(train_df)\n",
    "    tensor_structure = {'X':(range(-T+1, 1), train_df.columns[:1]), 'X2':(range(1, HORIZON+1), train_df.columns[1:])}\n",
    "    train_inputs = TimeSeriesTensor(train_df, 'value', HORIZON, tensor_structure)\n",
    "    test_inputs = TimeSeriesTensor(test_df, 'value', HORIZON, tensor_structure)\n",
    "    return train_inputs, test_inputs, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(l, drop, n, lr):\n",
    "    if l==1:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.LSTM(n, input_shape=(HORIZON, 14)),\n",
    "            tf.keras.layers.Dense(HORIZON)\n",
    "        ])\n",
    "    elif l==2:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "            tf.keras.layers.LSTM(n, input_shape=(HORIZON, 14), return_sequences=True),\n",
    "            tf.keras.layers.Dropout(drop),\n",
    "            tf.keras.layers.LSTM(n),\n",
    "            # Shape => [batch, time, features]\n",
    "            tf.keras.layers.Dense(HORIZON)\n",
    "        ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer=opt,metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def format_output(df):\n",
    "    df['h'] = df['h'].str.extract('(\\d+)', expand=False).astype(int)\n",
    "    ppivot = pd.pivot_table(df, values='prediction', index=['timestamp'], columns=['h'])\n",
    "    ppivot = ppivot.add_prefix('h_')\n",
    "    ppivot.index = pd.to_datetime(ppivot.index)\n",
    "    apivot = pd.pivot_table(df, values='actual', index=['timestamp'], columns=['h'])\n",
    "    apivot = apivot.add_prefix('h_')\n",
    "    apivot.index = pd.to_datetime(ppivot.index)\n",
    "    return ppivot, apivot\n",
    "\n",
    "def flatten(data):\n",
    "    flat_list = []\n",
    "    # iterating over the data\n",
    "    for item in data:\n",
    "        # appending elements to the flat_list\n",
    "        flat_list += item\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "names = []\n",
    "for i in range(1,29):\n",
    "    filename = '../data/Columbia_clean/Residential_'+str(i)+'.csv'\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    datasets.append(df)\n",
    "    names.append('B'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMIMO = load_model('./models/Columbia_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(datasets):\n",
    "        concat_input = tf.concat([dX_test[i]['X'],dX_test[i]['X2']], axis=2)\n",
    "        FD_predictions = LSTMIMO.predict(concat_input)\n",
    "        FD_eval_df = create_evaluation_df(FD_predictions, dX_test[i], HORIZON, dX_scaler[i], dXtest_scaler[i])\n",
    "        preds, actuals = format_output(FD_eval_df)\n",
    "        preds = preds[np.where(preds.index.hour == 0)[0][0]:][::24]\n",
    "        actuals = actuals[np.where(actuals.index.hour == 0)[0][0]:][::24]\n",
    "        full = actuals.merge(preds, how='inner', left_index=True, right_index=True, suffixes=('_actuals', '_preds'))\n",
    "        full.to_csv('./results/'+dset+'/'+wandb.run.name+'_'+str(i)+'.csv')\n",
    "        preds = flatten(preds.values.tolist())\n",
    "        actuals = flatten(actuals.values.tolist())\n",
    "        mae = validation(preds, actuals, 'MAE')\n",
    "        mape = validation(preds, actuals, 'MAPE')\n",
    "        rmse = validation(preds, actuals, 'RMSE')\n",
    "        #print('rmse {}'.format(rmse))\n",
    "        metrics.loc[i] = pd.Series({'mae':mae, 'mape':mape, 'rmse':rmse, 'B': names[i]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:evgeny] *",
   "language": "python",
   "name": "conda-env-evgeny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

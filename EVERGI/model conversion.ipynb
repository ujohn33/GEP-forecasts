{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "# Import mlcompute module to use the optional set_mlc_device API for device selection with ML Compute.\n",
    "#from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "# Select CPU device.\n",
    "#mlcompute.set_mlc_device(device_name='any') # Available options are 'cpu', 'gpu', and 'any'.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import src.preprocessing_3days\n",
    "from src.preprocessing_3days import series_to_supervised, preprocess\n",
    "from src.functions import load_data, TimeSeriesTensor, create_evaluation_df, plot_train_history, validation, save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, n_test, horizon):\n",
    "    if len(df) < 8760:\n",
    "        n_test = round(len(df) * 0.2)\n",
    "    test_df = df.copy()[-(n_test+horizon-1):]\n",
    "    train_df = df.copy()[:-(len(test_df)-horizon+1)]\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def MIMO_fulldata_preparation(df, n_test=4380, T=72, HORIZON=72, country='Canada'):\n",
    "    df = df.merge(series_to_supervised(df), how='right', left_index=True, right_index=True)\n",
    "    df = preprocess(df, country)\n",
    "    train_df, test_df = train_test_split(df, n_test, horizon=HORIZON)\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_scaler.fit(train_df[['value']])    \n",
    "    long_scaler = MinMaxScaler()\n",
    "    train_df[train_df.columns] = long_scaler.fit_transform(train_df)\n",
    "    test_df[test_df.columns] = long_scaler.transform(test_df)\n",
    "    tensor_structure = {'X':(range(-T+1, 1), train_df.columns[:1]), 'X2':(range(1, HORIZON+1), train_df.columns[1:])}\n",
    "    train_inputs = TimeSeriesTensor(train_df, 'value', HORIZON, tensor_structure)\n",
    "    test_inputs = TimeSeriesTensor(test_df, 'value', HORIZON, tensor_structure)\n",
    "    return train_inputs, test_inputs, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(l, drop, n, lr):\n",
    "    if l==1:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.LSTM(n, input_shape=(HORIZON, 14)),\n",
    "            tf.keras.layers.Dense(HORIZON)\n",
    "        ])\n",
    "    elif l==2:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "            tf.keras.layers.LSTM(n, input_shape=(HORIZON, 14), return_sequences=True),\n",
    "            tf.keras.layers.Dropout(drop),\n",
    "            tf.keras.layers.LSTM(n),\n",
    "            # Shape => [batch, time, features]\n",
    "            tf.keras.layers.Dense(HORIZON)\n",
    "        ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer=opt,metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def format_output(df):\n",
    "    df['h'] = df['h'].str.extract('(\\d+)', expand=False).astype(int)\n",
    "    ppivot = pd.pivot_table(df, values='prediction', index=['timestamp'], columns=['h'])\n",
    "    ppivot = ppivot.add_prefix('h_')\n",
    "    ppivot.index = pd.to_datetime(ppivot.index)\n",
    "    apivot = pd.pivot_table(df, values='actual', index=['timestamp'], columns=['h'])\n",
    "    apivot = apivot.add_prefix('h_')\n",
    "    apivot.index = pd.to_datetime(ppivot.index)\n",
    "    return ppivot, apivot\n",
    "\n",
    "def flatten(data):\n",
    "    flat_list = []\n",
    "    # iterating over the data\n",
    "    for item in data:\n",
    "        # appending elements to the flat_list\n",
    "        flat_list += item\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "names = []\n",
    "for i in range(1,29):\n",
    "    filename = '../data/Columbia_clean/Residential_'+str(i)+'.csv'\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    datasets.append(df)\n",
    "    names.append('B'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "names = []\n",
    "hourly = pd.read_csv('../data/London_smart_meters/London_hourly_all.csv', index_col='tstp')\n",
    "for house in hourly['LCLid'].unique():\n",
    "    temp = hourly.loc[hourly['LCLid'] == house]\n",
    "    datasets.append(temp)\n",
    "    names.append(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "LSTMIMO = load_model('./models/London_models/global_skilled-frog-284')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_test = []\n",
    "dX_scaler = []\n",
    "HORIZON = 72\n",
    "country = 'UK'\n",
    "dset = 'London'\n",
    "run_name = 'scaled_life'\n",
    "metrics = pd.DataFrame(columns=['mae','mape', 'rmse', 'B'], index=range(28))\n",
    "for i,df in enumerate(datasets):\n",
    "        train_inputs, test_inputs, y_scaler = MIMO_fulldata_preparation(df, n_test=4380, T=HORIZON, HORIZON=HORIZON, country=country)\n",
    "        dX_test.append(test_inputs)\n",
    "        dX_scaler.append(y_scaler)\n",
    "        concat_input = tf.concat([dX_test[i]['X'],dX_test[i]['X2']], axis=2)\n",
    "        FD_predictions = LSTMIMO.predict(concat_input)\n",
    "        FD_eval_df = create_evaluation_df(FD_predictions, dX_test[i], HORIZON, dX_scaler[i])\n",
    "        preds, actuals = format_output(FD_eval_df)\n",
    "        preds = preds[np.where(preds.index.hour == 0)[0][0]:][::24]\n",
    "        actuals = actuals[np.where(actuals.index.hour == 0)[0][0]:][::24]\n",
    "        full = actuals.merge(preds, how='inner', left_index=True, right_index=True, suffixes=('_actuals', '_preds'))\n",
    "        #full.to_csv('./results/'+dset+'/'+wandb.run.name+'_'+str(i)+'.csv')\n",
    "        preds = flatten(preds.values.tolist())\n",
    "        actuals = flatten(actuals.values.tolist())\n",
    "        mae = validation(preds, actuals, 'MAE')\n",
    "        mape = validation(preds, actuals, 'MAPE')\n",
    "        rmse = validation(preds, actuals, 'RMSE')\n",
    "        #print('rmse {}'.format(rmse))\n",
    "        metrics.loc[i] = pd.Series({'mae':mae, 'mape':mape, 'rmse':rmse, 'B': names[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142703</td>\n",
       "      <td>55.1483</td>\n",
       "      <td>0.233879</td>\n",
       "      <td>MAC000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0946562</td>\n",
       "      <td>73.3898</td>\n",
       "      <td>0.171266</td>\n",
       "      <td>MAC001814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0830018</td>\n",
       "      <td>78.3001</td>\n",
       "      <td>0.116079</td>\n",
       "      <td>MAC003721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152296</td>\n",
       "      <td>42.945</td>\n",
       "      <td>0.248323</td>\n",
       "      <td>MAC003341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0485388</td>\n",
       "      <td>62.7109</td>\n",
       "      <td>0.0705173</td>\n",
       "      <td>MAC001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.113</td>\n",
       "      <td>79.7984</td>\n",
       "      <td>0.251225</td>\n",
       "      <td>MAC003618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.297379</td>\n",
       "      <td>68.4857</td>\n",
       "      <td>0.470528</td>\n",
       "      <td>MAC001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.330143</td>\n",
       "      <td>80.6212</td>\n",
       "      <td>0.500765</td>\n",
       "      <td>MAC003622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.273642</td>\n",
       "      <td>62.6549</td>\n",
       "      <td>0.413132</td>\n",
       "      <td>MAC002385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.235204</td>\n",
       "      <td>86.2149</td>\n",
       "      <td>0.421642</td>\n",
       "      <td>MAC002195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mae     mape       rmse          B\n",
       "0    0.142703  55.1483   0.233879  MAC000020\n",
       "1   0.0946562  73.3898   0.171266  MAC001814\n",
       "2   0.0830018  78.3001   0.116079  MAC003721\n",
       "3    0.152296   42.945   0.248323  MAC003341\n",
       "4   0.0485388  62.7109  0.0705173  MAC001688\n",
       "..        ...      ...        ...        ...\n",
       "85      0.113  79.7984   0.251225  MAC003618\n",
       "86   0.297379  68.4857   0.470528  MAC001611\n",
       "87   0.330143  80.6212   0.500765  MAC003622\n",
       "88   0.273642  62.6549   0.413132  MAC002385\n",
       "89   0.235204  86.2149   0.421642  MAC002195\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HORIZON == 72:\n",
    "    metrics.to_csv('./results/'+dset+'/global/3days/LSTM_'+run_name+'.csv')\n",
    "if HORIZON == 24:\n",
    "    metrics.to_csv('./results/'+dset+'/global/dayahead/LSTM_'+run_name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32281072733376137\n"
     ]
    }
   ],
   "source": [
    "print(metrics['rmse'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.21196991935187\n"
     ]
    }
   ],
   "source": [
    "print(metrics['mape'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:evgeny] *",
   "language": "python",
   "name": "conda-env-evgeny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
